{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "This notebook explores creating a collaborative filtering model, a.k.a. a recommender system by using the data from [MovieLens](https://grouplens.org/datasets/movielens/100k/) and code direction by Jeremy Howard in the FastAI course 'Pracitcal Deep Learning for Coders'. The model is developed using the dot product method and provides the top 10 movie recommendations based on a movie input from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ML_100k) # data from MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The README file explains that the <i>u.data</i> file contains the user, movie, rating and timestamp in a tab-seperated format with 100k entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating  timestamp\n",
       "0   196    242       3  881250949\n",
       "1   186    302       3  891717742\n",
       "2    22    377       1  878887116\n",
       "3   244     51       2  880606923\n",
       "4   166    346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
    "                      names=['user','movie','rating','timestamp']) # provide column names\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data of the movies from <i>u.item</i> to map the name of the movies to their IDs in the 'ratings' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie              title\n",
       "0      1   Toy Story (1995)\n",
       "1      2   GoldenEye (1995)\n",
       "2      3  Four Rooms (1995)\n",
       "3      4  Get Shorty (1995)\n",
       "4      5     Copycat (1995)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n",
    "                     usecols=(0,1), names=('movie','title'), header=None)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>875747190</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>883888671</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>879138235</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>876503793</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating  timestamp         title\n",
       "0   196    242       3  881250949  Kolya (1996)\n",
       "1    63    242       3  875747190  Kolya (1996)\n",
       "2   226    242       5  883888671  Kolya (1996)\n",
       "3   154    242       3  879138235  Kolya (1996)\n",
       "4   306    242       5  876503793  Kolya (1996)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.merge(movies)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataloader using the factory method for <i>CollabDataLoaders</i>. Since we are loading the data from a dataframe, the method assumes the first column to be the user, the second column to be the movie and the third to be the rating for that movie. To make the dataloader readable, we use the movie title instead of movie ID using the item_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295</td>\n",
       "      <td>Seven (Se7en) (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>Interview with the Vampire (1994)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>347</td>\n",
       "      <td>Ghost and the Darkness, The (1996)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>561</td>\n",
       "      <td>Terminator, The (1984)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167</td>\n",
       "      <td>Waterworld (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>405</td>\n",
       "      <td>Poison Ivy II (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>864</td>\n",
       "      <td>Demolition Man (1993)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>314</td>\n",
       "      <td>Clerks (1994)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>559</td>\n",
       "      <td>Apocalypse Now (1979)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64) # bs - batch size\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop a recommender system, the model needs to learn the user's likes and dislikes in movies. Each movie can have several defining factors - for e.g. action, comedy, drama, romance, romedy, thriller, etc. Similarly, a user can also have factors that are determined by the kind of movies they like and rate. To recommend movies to a user, a relationship between the factors of the users and movies need to be forumlated . Not all users will have watched and rated all movies. For this, FastAI's collab_learner uses Stochastic Gradient Descent (SGD) and weigth decay (L2 Regularisation) to determine weights for each factor that will help recommend movies to the user. \n",
    "\n",
    "Before diving into the creating a learner, we can take a look at the data the dataloader has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users are 944 and number of the unique movies are 1665 .\n"
     ]
    }
   ],
   "source": [
    "n_users = len(dls.classes['user'])\n",
    "n_movies = len(dls.classes['title'])\n",
    "print('The number of unique users are',n_users,'and number of the unique movies are', n_movies,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataloader, we can develop a learner. FastAI has its own collaborative filtering model that can be used. The model essentially carries out a dot product mutiplication between the latent factor matrices. For this dataset, 50 latent factors will be used, i.e. the movies and users will have 50 defining factors. The predictions by the learner needs to be a rating between 0 to 5. Based on the empherical discovery by the creators of FastAI, it is best to choose a value slightly higher than 5, here it is 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explaination:</b> There are two ways to develop a collaborative filter model - using dot product and deep learning. As mentioned before, the method used for this approach is dot product; which is why, the parameter 'use_nn' while creating the learner is by default set to <b>False</b>. Due to this, the learner uses [EmbeddingDotBias](https://docs.fast.ai/collab.html#EmbeddingDotBias) with the dataloader as a class, number of factors (n_factors) and range of ratings (y_range). This creates latent factors using embeddings for the users and items (movies) with the help of the number of factors and builds a model. The layers of the model contain the embeddings of the users and movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fit_one_cycle() to train the model with [Cyclical Learning Rates](https://iconof.com/1cycle-learning-rate-policy/) starting with 0.005. This approach uses Stochastic Gradient Descent (SGD) to learn the values of the weights i.e. latent factors. The weight decay (wd) or L2 Regularization helps in keeping the weights or parameters as low as posisble to avoid overfitting. The smaller the weight decay, the larger the penalty on the parameter gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.929023</td>\n",
       "      <td>0.924260</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.884289</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.707542</td>\n",
       "      <td>0.833720</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.584835</td>\n",
       "      <td>0.819985</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494990</td>\n",
       "      <td>0.821814</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-3, wd=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The valid_loss is calculated using MSELossFlat by default. The model contains trained weights for the users and items (movies) and a bias for every movie and item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingDotBias(\n",
       "  (u_weight): Embedding(944, 50)\n",
       "  (i_weight): Embedding(1665, 50)\n",
       "  (u_bias): Embedding(944, 1)\n",
       "  (i_bias): Embedding(1665, 1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick peak at the embeddings for the user latent factors can be seen as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.9443e-03,  1.1393e-04, -2.2330e-03,  ..., -3.2655e-03,\n",
       "         -5.3349e-05,  1.1588e-03],\n",
       "        [-2.1976e-01, -3.0741e-01, -6.1382e-02,  ..., -1.0371e-02,\n",
       "         -2.9328e-01, -1.9306e-01],\n",
       "        [-5.6712e-02,  5.9999e-02, -2.0124e-01,  ...,  1.6301e-01,\n",
       "         -8.8005e-02, -1.9988e-01],\n",
       "        ...,\n",
       "        [-9.6665e-02,  1.9842e-01, -6.5452e-02,  ...,  1.8390e-01,\n",
       "         -5.0774e-02, -8.9966e-02],\n",
       "        [-1.8747e-01,  1.9523e-01, -2.4048e-01,  ...,  1.9683e-01,\n",
       "          1.5150e-01, -5.1991e-02],\n",
       "        [-2.8145e-01,  5.2345e-02,  3.5268e-01,  ...,  2.6607e-01,\n",
       "         -2.2565e-01, -3.2856e-01]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.u_weight.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix contains weights (latent factors) for the 50 factors for every user. Similarly another matrix for the movies is generated as an embedding layer. There is only one bias value for each item and each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 295,  850,  202,  ..., 1399, 1318, 1501], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.i_bias.weight.squeeze().argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias correlates with the ratings of the movies. A higher bias indicates a higher rating, vice-a-versa for a lower bias. The least favoured and most favoured movies can be calculated by sorting the bias using the argsort(). The function argsort() sorts the array values and outputs indexes of the sorted values from the original array. Using this, we can calculate the 10 highest and lowest rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_list(value):\n",
    "    movie_bias = learn.model.i_bias.weight.squeeze()\n",
    "    if value == 'top':\n",
    "        val = True \n",
    "    else:\n",
    "        val = False\n",
    "        value = 'Lowest'\n",
    "    idxs = movie_bias.argsort(descending=val)[:10] \n",
    "    movies = [dls.classes['title'][i] for i in idxs]\n",
    "    movie_bias = learn.model.bias(movies, is_item=True)\n",
    "    mean_ratings = ratings.groupby('title')['rating'].mean() # get mean rating for each movie\n",
    "    movie_ratings = [(b, i, mean_ratings.loc[i]) for i,b in zip(movies,movie_bias)]\n",
    "    print('---10 {} rated movies are---'.format(value))\n",
    "    for i in range(0,len(movies)):\n",
    "        print('Movie:',movie_ratings[i][1],', Mean Rating:',round(movie_ratings[i][2],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the top 10 rated movies along with their ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---10 top rated movies are---\n",
      "Movie: Titanic (1997) , Mean Rating: 4.25\n",
      "Movie: Shawshank Redemption, The (1994) , Mean Rating: 4.45\n",
      "Movie: Star Wars (1977) , Mean Rating: 4.36\n",
      "Movie: L.A. Confidential (1997) , Mean Rating: 4.16\n",
      "Movie: Apt Pupil (1998) , Mean Rating: 4.1\n",
      "Movie: Schindler's List (1993) , Mean Rating: 4.47\n",
      "Movie: Good Will Hunting (1997) , Mean Rating: 4.26\n",
      "Movie: Rear Window (1954) , Mean Rating: 4.39\n",
      "Movie: Usual Suspects, The (1995) , Mean Rating: 4.39\n",
      "Movie: Silence of the Lambs, The (1991) , Mean Rating: 4.29\n"
     ]
    }
   ],
   "source": [
    "movie_list('top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the lowest rated movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---10 Lowest rated movies are---\n",
      "Movie: Children of the Corn: The Gathering (1996) , Mean Rating: 1.32\n",
      "Movie: Lawnmower Man 2: Beyond Cyberspace (1996) , Mean Rating: 1.71\n",
      "Movie: Body Parts (1991) , Mean Rating: 1.62\n",
      "Movie: Robocop 3 (1993) , Mean Rating: 1.73\n",
      "Movie: Crow: City of Angels, The (1996) , Mean Rating: 1.95\n",
      "Movie: Mortal Kombat: Annihilation (1997) , Mean Rating: 1.95\n",
      "Movie: Jury Duty (1995) , Mean Rating: 2.0\n",
      "Movie: Cable Guy, The (1996) , Mean Rating: 2.34\n",
      "Movie: Free Willy 3: The Rescue (1997) , Mean Rating: 1.74\n",
      "Movie: Amityville 1992: It's About Time (1992) , Mean Rating: 1.0\n"
     ]
    }
   ],
   "source": [
    "movie_list('low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can now be used to provide recommendations. This being a low scale model, for now, the model can only predict similar movies to the one provided by the user. This can be done by measuring the similarity between the provided movie and other movie and listing the top 5 closest members, thus providing a list of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_movie(title):\n",
    "    movie_factors = learn.model.i_weight.weight\n",
    "    idx = dls.classes['title'].o2i[title]\n",
    "    distances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
    "    idx = distances.argsort(descending=True)[0:6]\n",
    "    movies = dls.classes['title'][idx]\n",
    "    num = 1\n",
    "    for i in movies:\n",
    "        print(num,'- ', i)\n",
    "        num += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 similar movies to Star Wars (1977) are:\n",
      "1 -  Star Wars (1977)\n",
      "2 -  Empire Strikes Back, The (1980)\n",
      "3 -  Return of the Jedi (1983)\n",
      "4 -  Raiders of the Lost Ark (1981)\n",
      "5 -  Fresh (1994)\n",
      "6 -  Sting, The (1973)\n"
     ]
    }
   ],
   "source": [
    "movie = 'Star Wars (1977)'\n",
    "print('The top 5 similar movies to {} are:'.format(movie))\n",
    "similar_movie(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprising that the movies similar to the 1977 Star Wars movie are the subsequent movies of the same franchise followed by the action/adventure Indiana Jones movie. The weights for the last 2 movies seem to be similar to Star Wars, meaning the drama genre is closely related to the action/adventure genre. Let's try it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 similar movies to Forrest Gump (1994) are:\n",
      "1 -  Forrest Gump (1994)\n",
      "2 -  Field of Dreams (1989)\n",
      "3 -  Hunt for Red October, The (1990)\n",
      "4 -  It's a Wonderful Life (1946)\n",
      "5 -  American President, The (1995)\n",
      "6 -  Shawshank Redemption, The (1994)\n"
     ]
    }
   ],
   "source": [
    "movie = \"Forrest Gump (1994)\"\n",
    "print('The top 5 similar movies to {} are:'.format(movie))\n",
    "similar_movie(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full scale model will be more informed with with data based more on demographic of the users. For now, this model can provide us with 5 movies at a time to watch the next time a lockdown is announced in case of a pandemic (heavens forbid!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
